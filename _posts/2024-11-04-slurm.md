---
layout: post
author: Bruce Lee
title: Slurm
---

# 👨‍🎓 Slurm<br/><br/>

## Slurm
- Slurm은 리눅스 기반 클러스터에서 활용되는 스케줄러 또는 리소스 매니저이다.
- 서버 여러 대에 퍼져있는 GPU 등의 리소스를 효율적으로 쓸 수 있게 도와준다.
- GPU 수요가 몰리는 기간이 다르니 노는 GPU를 최소화하기 위해 만들어졌다.
- Singularity 와 Docker와 Kubernetes 와 같은 환경을 통해 구성 가능하다 
- 참조 아키텍처는 아래와 같다.
<br/><br/>Image from solutions.posit.co![Untitled](../assets/img/slurm/slurm01.png)<br/><br/>
- 쿠버네티스와 통합된 아키텍처는 다음과 같다.
<br/><br/>Image from solutions.posit.co![Untitled](../assets/img/slurm/slurm02.png)<br/><br/>


## 스케쥴러
- CPU/GPU 등의 컴퓨팅 자원을 특정 시간 동안 다른 유저의 방해를 받지 않고 독점적으로 쓰게 하고 싶을 경우 리소스 매니저 혹은 스케쥴러가 필요하다
- 스케쥴러 덕분에 유저는 GPU 가용 자원을 매번 확인 하지 않아도 되고 본인 소유의 GPU 를 다른 유저가 사용해 OOM 이 발생할 걱정을 하지 않아도 된다.
- Slurm 스케쥴러의 기능
  - 리소스 모니터링 : 간단한 명령어를 통해 현재 GPU를 누가 쓰고 있는지, job이 몇 개 대기 중인지, 노드 상태가 어떤지 등을 알 수 있다.
  - 리소스 스케줄링 : 유저가 요구한 만큼의 자원이 있으면 바로 빌려주고 없으면 대기시킨다. 자원이 비면 바로 할당시켜준다. 그리고 슬럼은 다른 리소스 매니저보다 더 유연한 스케줄링 정책을 갖고 있다. 대표적으로 backfilling이라는 건데 job들이 리소스를 기다리면서 줄 서있을 때 뒷사람이 할 일이 적다면 먼저 보내주는(할당시켜주는) 기능이다.
  - Fine-grained resource manging : 다른 리소스 매니저에는 없는 굉장히 세부적인 리소스 제한 방식을 제공한다. 이를 통해 권한자 및 관리자는 더 세부적인 리소스 정책을 펼칠 수 있다. Accounting 기능을 통해 특정 그룹군 별로 리소스 제한이 가능하다.
  - Job array : Job 하나를 여러 개 복사해서 제출할 수 있다. 완전히 똑같은 건 아니고 각 세션마다 JOB_ARRAY_TASK_ID 라는 환경변수 값이 달라진다. 이를 이용해 hyper-parameter search를 할 수 있다.
  - Prioritization : 대기 중인 job이 많을 때 리소스가 비면 먼저 투입되는 순서를 정할 수 있다.
  - FairShare이라는 기능으로 유저의 최근 리소스 사용량을 기반으로 유저의 job 우선순위를 계산하게 할 수도 있다. GPU를 적게 사용한 사람이 job을 제출하면 줄 맨앞으로 보내주는 식이다.
  - Partition : 여러 옵션이 pre-set 되어있는 노드 집합 정도로 생각하면 될 것 같다. Job을 제출할 때 반드시 파티션을 하나 이상 명시해야 한다. 파티션은 기본적으로 노드 집합이고, 해당 파티션을 쓸 수 있는 (유저)그룹 또는 슬럼의 기능인 account 등등을 명시해서 노드들을 분리하여 사용자 그룹이 사용할 수 있는 노드들을 제한하는 역할을 수행한다.
  - Requeue : Running 중인 job을 job 주인이 requeue 및 hold 시킬 수 있다. 누군가 급하게 잠깐 쓴다고 할 때 쓰면 좋다.
  - Job 예약 기능 : 제출된 job을 언제부터 돌릴지 예약할 수 있다.
- Slurm 스케쥴러의 단점
  - Microservice들(에 해당하는 job들)을 체계적으로 켜고 끄고가 안 된다. 따라서 서비스 배포 목적으로는 부적절하다.
  - VSCode-jupyter, GUI debugger 등에 GPU를 쓰겠다 하면 srun 으로 GPU를 할당 받고 할당 된 노드에서 프로그램을 또 켜야 하기 때문에 번거롭다.

## Slurm vs k8s<br/><br/>
- 만약 HPC로 활용할 목적이라면 온프레미스가 아니더라도 클라우드 위에 Slurm 등의 스케줄러가 필요하다.
- TOP500 슈퍼컴퓨터 중 반 이상, TOP10 중 6개가 Slurm을 사용 중이다.
- 메타, 구글 클라우드는 Slurm 쓴다.

### 써보신 분 의견
> HPC 목적으로 쿠버, Slurm 둘 다 써본 사람이 많지 않고 쿠버는 데브옵스 쪽에서 무소불위의 SOTA이기 때문에 친숙한 사람들이 매우 많다.<br/>
> 그래서 HPC usage 쪽에서도 쿠버 손을 들어주는 쪽이 많은 것 같다. 하지만 쿠버는 유저에게 containerization 오버헤드를 강제하고, 보안 및 라우팅 목적의 네트워크 분리 등은 모델 학습 시 필요가 없다.<br/>
> 오히려 퍼포먼스에 방해가 된다. 이러한 batch job들은 로그 찍고, 체크포인트만 뱉어주면 된다. 그리고 Slurm의 backfill, multi-level QoS, Fairshare 등의 리소스 최적화 스케줄링은 쿠버의 로드밸런서, 서드파티 batch job 스케줄러 플러그인보다 HPC에 적합하다고 생각한다.